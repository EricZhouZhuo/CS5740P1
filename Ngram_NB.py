# -*- coding: utf-8 -*-
"""Copy of CS4740_FA21_p1_zz274_jg929.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u7EfMJ1aVojd3MV1JMTOWyfsdGZqMLlt
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!pip install -U nltk tqdm

import os
import csv
import io
from nltk import word_tokenize, sent_tokenize
import nltk
from tqdm.notebook import tqdm
nltk.download('punkt')

root_path = os.path.join(os.getcwd(), "drive", "My Drive/NLP Project") 
dataset_path = os.path.join(root_path) # same here

real_review_train = []
real_review_validation = []
fake_review_train = []
fake_review_validation = []

def load_real_fake_dataset(dataset_path, filename):
    real = []
    fake = []
    with open(os.path.join(dataset_path, filename)) as fp:
        csvreader = csv.reader(fp, delimiter="|")
        for txt, label in csvreader:
            label = int(label)
            if label:
                fake.append(txt)
            else:
                real.append(txt)
    
    return real, fake

real_review_train, fake_review_train = load_real_fake_dataset(dataset_path,
                                              "P1_real_fake_review_train.txt")

real_review_validation, fake_review_validation = load_real_fake_dataset(dataset_path,
                                                "P1_real_fake_review_val.txt")

def load_test_dataset(dataset_path, filename):
    output = []
    with open(os.path.join(dataset_path, filename)) as fp:
        csvreader = csv.reader(fp, delimiter=" ")
        for id, text in csvreader:
          output.append(text)
    output.pop(0)
    return output
f_test = load_test_dataset(dataset_path,"P1_real_fake_review_test.txt" )

def tokenize_reviews(reviews):
    return [
        [
            word.lower() for sent in sent_tokenize(review)
            for word in word_tokenize(sent)
        ]
        for review in tqdm(reviews, leave=False)
    ]

# Tokenizing our real review training data
tokenized_real_review_training = tokenize_reviews(real_review_train)

# Tokenizing our fake review training data
tokenized_fake_review_training = tokenize_reviews(fake_review_train)        

# Combining our tokenized real and fake review training data
tokenized_review_training = tokenized_real_review_training + tokenized_fake_review_training

# Tokenizing our real review validation data
tokenized_real_review_validation = tokenize_reviews(real_review_validation)  

# Tokenizing our fake review validation data
tokenized_fake_review_validation = tokenize_reviews(fake_review_validation)      

# Combining our tokenized real and fake review validation data
tokenized_review_validation = tokenized_real_review_validation + tokenized_fake_review_validation

# Tokenizing our test data
tokenized_review_test = tokenize_reviews(f_test)

# tokenized_real_review_training[0]

# ****  FUNCTION - lbltble(rvw,label=0) *******
'''
Purpose:
To create a table with reviews column and indicator column for "real or "fake" reviews  

Arguments:
rvw: list of reviews
label: indicator value we wish to assign to a column  of the table

Returns:
A final table with review and indicator column differentiating the "real " and "fake" reviews

'''

def lbltble(rvw,label=0): 
  import pandas as pd
  df_review = pd.DataFrame(rvw, columns = ["Review"])# Creating a "Review" colum in our dataframe
  df_review["y"]=label                 # Labelling our reviews
  return df_review

# Our true and fake training reviews constructed in tables
df_real_review_train= lbltble(real_review_train,0)
df_fake_review_train = lbltble(fake_review_train,1)

# Our true and fake validation reviews constructed in tables
df_real_review_valid = lbltble(real_review_validation,0)
df_fake_review_valid = lbltble(fake_review_validation,1)

# Our test reviews constructed in tables
df_test_review = lbltble(f_test)

# Combined (true and fake) review trainig & validation data
import pandas as pd

df_review_train = pd.concat([df_real_review_train,df_fake_review_train], axis=0).reset_index(drop=True)
df_review_valid = pd.concat([df_real_review_valid,df_fake_review_valid], axis=0).reset_index(drop=True)

# ****  FUNCTION - rmvspchr_reviews(tknzd_rev)  *******
'''
Purpose:
Remove the non alphabetics tokens

Arguments:
tknzd_rev: tokenized text

Returns:
tokenized text without elements in our pre-defined non alphabetics list

'''
def rmvspchr_reviews(tknzd_rev):
    # Special characters to be removed from our list
    special_char = ["(", ")", ".", ",", "..","...","....","''",":","`","``","```","-","--","_","__",";","_ _","[","]"]  
    for idx, text in enumerate(tknzd_rev):
      for word in text:
        if word in special_char:
          tknzd_rev[idx].remove(word) # Removing the special characters from our input list                          
    return tknzd_rev

# ****  FUNCTION - freq_wrd(tknzd_rvw, n)  *******
'''
Purpose:
Remove the stop words

Arguments:
tknzd_rev: tokenized text

Returns:
tokenized text without elements the stopwords package from nltk.corpus

'''
def rmv_stpwor(tknzd_rev):
  from nltk.corpus import stopwords     # Importing the stopwords from NLTK library
  nltk.download('stopwords')
  stop_words = set(stopwords.words('english'))

  # Removing all such stop words from the list
  p = [[t for t in q if t not in stop_words] for q in tknzd_rev]                          
  return p

# **********************  CLASS - stats_disp  ************************************

'''
Purpose:
Show some observations or statistics from the dataset. 

Has the following functions to help with the same:
1. unigram_dic(lst) - to generate a unigram words count dictionary
2. bigram_dic(lst) - 
3. freq_wrd(tknzd_rvw, n) - to display frequency based statistics via histogram plots
4. num_stat() - to display numerical statistics of the data used in this project
'''
import matplotlib.pyplot as plt
import numpy as np
import nltk
nltk.download("stopwords")
from nltk.corpus import stopwords

class stats_disp:

  # ****  FUNCTION - unigram_dic(lst)  *******
  '''
  Purpose:
  Generate a dictionary to store unigram words and counts, and used to 
  calculate he unigram/bigram probabilities.

  Arguments:
  lst: input list of corpus

  Returns:
  A dictionary of unigram words and count
  ---{Key : Count}

  '''
  def unigram_dic(self,lst):
        unigrams={}
        lst = rmv_stpwor(rmvspchr_reviews(lst))  
        for l in lst:
          for i in range(len(l)): 
              if l[i] in unigrams:
                  unigrams[l[i]] += 1
              else:
                  unigrams[l[i]] = 1
        return unigrams

  # ****  FUNCTION - bigram_dic(lst)  *******
  '''
  Purpose:
  Calculate the bigram tuple counts and store into a dictionary

  Arguments:
  lst: input list of corpus

  Returns:
  A bigram dictionary of words tuple and probability
  ---{Tuple : Count}

  '''
  def bigram_dic(self,lst):
      bidic={}
      lst = rmv_stpwor(rmvspchr_reviews(lst))
      for l in lst:
        for i in range(len(l) - 1):
          temp = (l[i], l[i+1]) 
        if not temp in bidic:
            bidic[temp] = 1
        else:
            bidic[temp] += 1
      return bidic  

  # ****  FUNCTION - freq_wrd(tknzd_rvw, n)  *******

  '''
  Purpose:
  Show some observations or statistics from the dataset. Basically to show the most
  frequent unigram words and bigram words as well as histograms

  Arguments:
  tknzd_rvw: tokenized text after data pre-processing
  n: first N unigram words/bigram words sorted from highest to lowest frequency

  Returns:
  Plot bar graphs to show the frequencys for unigram and bigram words
  '''

  def freq_wrd(self,tknzd_rvw, n, ngram):
        if ngram =="unigram":
          dic = self.unigram_dic(tknzd_rvw)                             # Creating a unigram dictionary from the list of tokens
        elif ngram =="bigram":
          dic = self.bigram_dic(tknzd_rvw)                               # Creating a bigram dictionary from the list of tokens
        sort_dic=dict(sorted(dic.items(), key=lambda item: item[1], reverse=True)) # Sorting the dictionary based on the values in descsending order
        res_uni = dict(list(sort_dic.items())[0: n]) 
                            # Trimming dictionary to retain only the first n items
        plt.title("Most Frequent {0} words in training data".format(ngram),fontdict = {'fontsize' : 20})
        plt.rcParams["figure.figsize"] = (70, 10)                               # Adjusting fig size to 80 by 80 dimensions
        plt.bar([str(i) for i in res_uni.keys()], res_uni.values())                # X axis tick labels
        plt.xticks(fontsize=20)
        plt.yticks(fontsize=20)
        print(res_uni) 

  def num_stats(self,tknzd_rvw):
        sents = nltk.sent_tokenize(str(tknzd_rvw))             # Tokenizing our review list into sentences
        print("The number of sentences is", len(sents))
        words = nltk.word_tokenize(str(tknzd_rvw))              # Tokenizing our review list into words
        print("The number of tokens is", len(words))
        average_tokens = round(len(words)/len(sents))
        print("The average number of tokens per sentence is",average_tokens)
        word_type = set(words)                                        # Creating a unique list of words
        print("The number of word types are", len(word_type))
        stop_words = set(stopwords.words('english'))
        final_tokens = []
        for each in words:
          if each not in stop_words:
            final_tokens.append(each)
        print("The number of total tokens after removing stopwords are", len((final_tokens)))

stat_displayer = stats_disp()                             # Instantiating the stats_display class
stat_displayer.num_stats(tokenized_review_training)       # Displaying statistics for tokens

stat_displayer.freq_wrd(tokenized_review_training,15,"unigram")

stat_displayer.freq_wrd(tokenized_review_training,15,"bigram")

import pandas as pd

# ****  FUNCTION - unsmoothed_unigram_dic(lst)  *******

'''
Purpose:
Generate a dictionary to store unigram words and counts, and used to 
calculate he unigram/bigram probabilities.

Arguments:
lst: input list of corpus

Returns:
A dictionary of unigram words and count
---{Key : Count}

'''

def unsmoothed_unigram_dic(lst):
  unigrams={}                                # Moving through every position in our list of list of words
  for l in lst:
    for i in range(len(l)): 
        if l[i] in unigrams:
            unigrams[l[i]] += 1              # Incrementing the unigram dictionary values for every word found 
        else:
            unigrams[l[i]] = 1
  return unigrams

# ****  FUNCTION - unsmoothed_unigram_prob(lst, unigram_dic)  *******

'''
Purpose:
Calculate the probability of unigram words and store into a dictionary

Arguments:
lst: input list of corpus
unigram_dic: the dictionary of unigram words and count

Returns:
A separate unigram dictionary of words and probability
---{Key : Probability}
'''

def unsmoothed_unigram_prob(lst, unigram_dic):
  deno_cnst = sum(unigram_dic.values()) 
  for key, value in unigram_dic.items():  # Traversing through key value pairs in the unigram dictionary
    # do something with value
    # Generating the unigram probability based on the unigram count from the unigram dictionary and total no of words in our list
        unigram_dic[key] = unigram_dic[key]/(deno_cnst) 
  return unigram_dic

import pandas as pd

# ****  FUNCTION - unsmoothed_bigram_dic(lst)  *******

'''
Purpose:
Calculate the bigram tuple counts and store into a dictionary

Arguments:
lst: input list of corpus

Returns:
A bigram dictionary of words tuple and probability
---{Tuple : Count}

'''

def unsmoothed_bigram_dic(lst):
    bigrams={}                                           # An empty dictionary to store bigram tuples
    for l in lst:
      for i in range(len(l) - 1):                        # Moving through every position in our list of list of words
        temp = (l[i], l[i+1])                            # Generating bigram tuple based on the position
        if not temp in bigrams:
            bigrams[temp] = 1                            # Incrementing the bigram dictionary values for every word found 
        else:
            bigrams[temp] += 1
    return bigrams  

# ****  FUNCTION - unsmoothed_bigram_prob(lst,unigram_dic,bigram_dic)  *******

'''
Purpose:
Calculate the bigram tuple probabilities and store into a dictionary

Arguments:
lst: input list of corpus
unigram_dic: unigram words counts used to be the denominators for calculating
probabilities of bigram tuple
bigram_dic: dictionary of bigram tuples and counts

Returns:
A bigram dictionary of words tuple and probability
---{Tuple : Probability}

''' 
def unsmoothed_bigram_prob(lst,unigram_dic,bigram_dic):
    unsmoothed_bigram_pro ={}
    for key, value in bigram_dic.items():       # Traversing through key value pairs in the bigram dictionary
    # do something with value
    # Generating the bigram probability based on the count of the bigram tuple 
    # from the bigram dictionary and the unigram count from the unigram dictionary
        unsmoothed_bigram_pro[key] = bigram_dic[key]/unigram_dic[key[0]]        
    return unsmoothed_bigram_pro

# ****  FUNCTION - replace_oov_words_by_unk(tknzd_rev) *******
"""
    Purpose : To replace words not in the given vocabulary with 'UNK' token. 
              The definition for our vocabulary includes every word with more than 1 occurence from the list of sentences 
    
    Arguments:
        tknzd_rev: List of lists of strings
    
    Returns:
        List of lists of strings, with words not in the vocabulary replaced with "UNK"
    """

def replace_oov_words_by_unk(tknzd_rev):
    rpl_lst=[]
    dic = unsmoothed_unigram_dic(tknzd_rev)
    not_vocabulary = [k for k in dic if dic[k] ==1]

    for l in tknzd_rev:
      for w in range(len(l)):
        # test if word w is in vocabulary
        if l[w] in not_vocabulary:
            l[w] = "UNK"
    return tknzd_rev

# ****  FUNCTION - add_k_unigram_prob(unigram_dic, k) *******
'''
Purpose:
Apply smoothing on unigram probabilities dic

Arguments:
unigram_dic: a dictionary of your unigrams
k: smoothing parameters

Returns:
a dictionary of results after smoothing

'''
def add_k_unigram_prob(unigram_dic, k):
  # TODO
    smoothed_unigram_pro ={}
    vocab_siz = len(unigram_dic.keys())                # Total Vocabulary size
    adjst_deno_cnst = sum(unigram_dic.values()) + k*vocab_siz    # Adjusted denominator of total word counts used for unigram probability measure
    for key, value in unigram_dic.items():
    # do something with value
        smoothed_unigram_pro[key] = (unigram_dic[key] + k)/(adjst_deno_cnst)  # Smoothing the unigram probability value
    return smoothed_unigram_pro

# ****  FUNCTION - add_k_bigram_prob(unigram_dic,bigram_dic, k) *******
'''
Purpose:
Apply smoothing on bigram probabilities dic

Arguments:
unigram_dic: a dictionary of your unigrams.
bigram_dic: a dictionary of your bigrams.
k: smoothing parameters

Returns:
a dictionary of results after smoothing

'''
def add_k_bigram_prob(unigram_dic,bigram_dic, k):
  # TODO
    smoothed_bigram_pro ={}
    vocab_siz = len(unigram_dic.keys())
    for key, value in bigram_dic.items():
    # do something with value

    # Adjusted denominator of total word counts used for bigram probability measure  
        smoothed_bigram_pro[key] = (bigram_dic[key] + k)/(unigram_dic[key[0]] + k*(vocab_siz))   
    return smoothed_bigram_pro

# ****  FUNCTION - cumm_processing(self,tknzd_rvw,ngram,k) *******

'''
Purpose:
To preprocess our tokenized sentences before creating our language model 
classifier by removing special characters, stopwords and further treating it for unseen words and unknown words

Arguments:
tknzd_rvw:List of lists of strings
ngram: our choice for the ngram we are preprocessing (string value)
k: smoothing parameters

Returns:
a dictionary of probability values for our tokens after all preprocessing
'''
def cumm_processing(tknzd_rvw,ngram,k):
      no_spchctr = rmvspchr_reviews(tknzd_rvw)                    # Removing special characters
      no_spchctr_stp_wrd = rmv_stpwor(no_spchctr)                  # Removing stopwords
      replaced_no_sp_stp_wrd = replace_oov_words_by_unk(no_spchctr_stp_wrd)    # Replacing unknown words with "UNK"
      
      if ngram =="unigram":                                          # Choice of unigram or bigram
        #replaced_no_sp_stp_wrd = replace_oov_words_by_unk(tknzd_rvw)
        unsmoothed_dic = unsmoothed_unigram_dic(replaced_no_sp_stp_wrd)        # Creating a dictionary of unigram words based on input list of words
        # Creating a dictionary of unigram word probabilities based on input list of words 
        unsmoothed_prob = unsmoothed_unigram_prob(replaced_no_sp_stp_wrd,unsmoothed_unigram_dic(replaced_no_sp_stp_wrd))
        # Smoothing a dictionary of unigram words based on input list of words
        smoothed_replaced_prob= add_k_unigram_prob(unsmoothed_unigram_dic(replaced_no_sp_stp_wrd),k)      
        return smoothed_replaced_prob
      
      elif ngram =="bigram":
          #replaced_no_sp_stp_wrd = replace_oov_words_by_unk(tknzd_rvw)
          unsmoothed_dic = unsmoothed_bigram_dic(replaced_no_sp_stp_wrd)      # Creating a dictionary of bigram words based on input list of words     
          # Creating a dictionary of bigram word probabilities based on input list of words                                                                                                                          
          unsmoothed_prob = unsmoothed_bigram_prob(replaced_no_sp_stp_wrd,unsmoothed_unigram_dic(replaced_no_sp_stp_wrd),unsmoothed_bigram_dic(replaced_no_sp_stp_wrd))
          # Smoothing a dictionary of bigram words based on input list of words 
          smoothed_replaced_prob= add_k_bigram_prob(unsmoothed_unigram_dic(replaced_no_sp_stp_wrd),unsmoothed_bigram_dic(replaced_no_sp_stp_wrd) ,k)                    
          return smoothed_replaced_prob

# ****  FUNCTION - unigram_perplexity(lst, uni_prob) *******

'''
Purpose:
To generate the perplexity values for a given list of unigram words based on the probability values of the same words from a training set

Arguments:
lst:List of strings
uni_prob: our list of (preprocessed) unigram word probabilities from our training set

Returns:
Perplexity value for all the unigram words present both in the input list and our training set 
'''

def unigram_perplexity(lst, uni_prob):
  perplexity = []
  for word in lst:                           # Iterating through every word in the list
      if word in uni_prob:                   # Checking if the unigram tuple from the list is present in the unigram dictionary generated from our training data
        perplexity.append(-np.log(uni_prob[word]))  # Adding the negative logarithms of perplexity values to the perplexity list
  return np.exp(1.0 / len(perplexity) * sum(perplexity)) # Returning actual perplexity values

# ****  FUNCTION - bigram_perplexity(lst, bi_prob, uni_prob) *******

'''
Purpose:
To generate the perpelxity values for a given list of bigrams based on the
 probability values of the same set of words from a training set

Arguments:
lst:List of strings
bi_prob:our list of (preprocessed) bigram word probabilities from our training set
uni_prob: our list of (preprocessed) unigram word probabilities from our training set

Returns:
Perplexity value for all the bigram words present both in the input list and our training set 
'''


def bigram_perplexity(lst, bi_prob, uni_prob):
    perplexity = []
    for i in range(len(lst)-1):         # Iterating through position in the list
      bigramTuple = (lst[i], lst[i+1])  # Generating bigram tuple based on the position
      if bigramTuple in bi_prob:        # Checking if the bigram tuple from the list is present in the bigram dictionary generated from our training data
        perplexity.append(-np.log(bi_prob[bigramTuple]))    # Adding the negative logarithms of perplexity values to the perplexity list
    return np.exp(1.0 / len(perplexity) * sum(perplexity))  # Returning actual perplexity values

# ****  FUNCTION - unigramClassifier(tokens, truthfulProbs, deceptiveProbs) *******

'''
Purpose:
To preprocess our tokenized sentences before creating our language model 
classifier by removing special characters, stopwords and further treating 
it for unseen words and unknown words

Arguments:
tokens:List of lists of strings
truthfulProbs: Our final preprocessed list of unigram probabilities based on 
real reviews from the training set
deceptiveProbs: Our final preprocessed list of unigram probabilities based on 
fake reviews from the training set

Returns:
List of 1's and 0's for each review in the tokens based on the perplexity 
values of the reviews using training set's real and fake review probabilities. 
'''

def unigramClassifier(tokens, truthfulProbs, deceptiveProbs):
  result = []                                                   # Prediction list
  for idx,line in enumerate(tokens):
    truthfulPerplexity = unigram_perplexity(line, truthfulProbs) # Applying the unigram perplexity model on the list of "real review" probabilities
    deceptivePerplexity = unigram_perplexity(line, deceptiveProbs)  # Applying the unigram perplexity model on the list of "fake review" probabilities
    if truthfulPerplexity <= deceptivePerplexity:
      result.append(0)       # Assigning 0 (binary) prediction value to the review based on the lower of truthful and deceptive probablity values
    else:
      result.append(1)       # Assigning 1 (binary) prediction value to the review based on the lower of truthful and deceptive probablity values
  return result                      


# ****  FUNCTION - bigramClassifier(tokens, bitruthfulProbs, bideceptiveProbs, unitruthfulProbs, unideceptiveProbs) *******

'''
Purpose:
To preprocess our tokenized sentences before creating our language model 
classifier by removing special characters, stopwords and further treating it for unseen words and unknown words

Arguments:
tokens: List of lists of strings
bitruthfulProbs:Our final preprocessed list of bigram probabilities based on real reviews from the training set
bideceptiveProbs:Our final preprocessed list of bigram probabilities based on fake reviews from the training set
truthfulProbs: Our final preprocessed list of unigram probabilities based on real reviews from the training set
deceptiveProbs: Our final preprocessed list of unigram probabilities based on fake reviews from the training set


Returns:
List of 1's and 0's for each review in the tokens based on the perplexity 
values of the reviews using training set's real and fake review probabilities.
'''

def bigramClassifier(tokens, bitruthfulProbs, bideceptiveProbs, unitruthfulProbs, unideceptiveProbs):
  result = []                                          # Prediction list
  for idx,line in enumerate(tokens):
    # Applying the bigram perplexity model on the list of "real review" probabilities
    truthfulPerplexity = bigram_perplexity(line, bitruthfulProbs, unitruthfulProbs)     
    # Applying the bigram perplexity model on the list of "fake review" probabilities  
    deceptivePerplexity = bigram_perplexity(line, bideceptiveProbs, unideceptiveProbs)
    if truthfulPerplexity <= deceptivePerplexity:
      result.append(0)     # Assigning 0 (binary) prediction value to the review based on the lower of truthful and deceptive probablity values
    else:
      result.append(1)     # Assigning 1 (binary) prediction value to the review based on the lower of truthful and deceptive probablity values
  return result

# ****  FUNCTION - accuracy_val(valid_y, pred) *******

'''
Purpose:
To find the accuracy of a given prediction set based on a test set.

Accuracy = (# of correct predictions)/(# of values in the prediction set)

Arguments:
valid_y: List of actual binary values (0's and 1's) for real and fake reviews from test set
pred: List of predicted binary values for real and fake reviews generated by a model

Returns:
Accuracy results based on the total number of correct predictions made by model
'''

def accuracy_val(valid_y, pred):
  accuracy=0
  for i in range(len(valid_y)):
    if valid_y[i] == pred[i]:  # Checking if predicted values are equal the actual values from validation set
      accuracy+=1              # Incrementing the accuracy counter to take note of the correct predictions
  return accuracy/len(pred)

# Finding smooothed bigram and unigram probabilities seperately for real and fake reviews from training data

 # Applying the cummulative pocessing function on our tokenized real reviews choosing a unigram model
smoothed_process_unigram_prob_real = cumm_processing(tokenized_real_review_training,"unigram",0.2)

# Applying the cummulative pocessing function on our tokenized real reviews choosing a bigram model     
smoothed_process_bigram_prob_real = cumm_processing(tokenized_real_review_training,"bigram",0.00001) 

# Applying the cummulative pocessing function on our tokenized fake reviews choosing a unigram model
smoothed_process_unigram_prob_fake = cumm_processing(tokenized_fake_review_training,"unigram",0.2)  

# Applying the cummulative pocessing function on our tokenized fake reviews choosing a bigram model    
smoothed_process_bigram_prob_fake = cumm_processing(tokenized_fake_review_training,"bigram",0.00001)

"""The prediction values based on the unigram classifier are given below:"""

##Applying the unigram classifier on the validation dataset based on our obtained probabilities of real and fake reviews from training data
result_uni = unigramClassifier(tokenized_review_validation, smoothed_process_unigram_prob_real, smoothed_process_unigram_prob_fake)  
print(result_uni)

"""The prediction values based on the bigram classifier are given below:"""

result_bi = bigramClassifier(tokenized_review_validation, smoothed_process_bigram_prob_real, smoothed_process_bigram_prob_fake, smoothed_process_unigram_prob_real, smoothed_process_unigram_prob_fake)   ##Applying the bigram classifier on the validation dataset based on the above obtained probabilities of real and reviews from training data
print(result_bi)

"""The accuracy based on the unigram classifier is given below:"""

#Accuracy values calculated for unigram classifier based of the binary y values 0's (real reviews) and 1's (fake reviews) from validation data
accr_uni = accuracy_val(y_valid,result_uni)      
print(accr_uni)

"""The accuracy based on the bigram classifier is given below"""

#Accuracy values calculated for bigram classifier based of the binary y values (0's (real reviews) and 1's (fake reviews) from validation data )
accr_bi = accuracy_val(y_valid,result_bi)       
print(accr_bi)

pred = unigramClassifier(tokenized_review_test, smoothed_process_unigram_prob_real, smoothed_process_unigram_prob_fake)   # Applying the unigram classifer method to the test data
Predicted_1 = pd.DataFrame(pred, columns= ['Prediction'])                                                                 # Creating a dataframe with our predictions
Predicted['Id'] = range(0,160)                                                                                            # Creating an ID column for the same dataframe 
Predicted_1 = Predicted[['Id', 'Prediction']]                                                                             # Joining our ID and predictions dataframe into one
print(Predicted_1)

# TODO: Add code to generate the Kaggle output file and submit the output file to Kaggle
df = pd.DataFrame(result_uni, columns= ['Prediction'])
df.to_csv("unigram.csv")

!cp unigram.csv "drive/My Drive/"

# ****  FUNCTION - nb_classifier(test_data,train_real_data,train_fake_data,model) *******

'''
Purpose:
To use the Naive Bayes (NB) Classifier and predict whetehr a given test review 
is real or fake and also further find the accuracy of a given prediction value set based on a test set

Arguments:
test_data: Test data whose real or fake labels we are predicting
train_data: Reviews training data which is used to train our NB classifer
model:Count vectorizer or tfidf vectorizer counts for the number of words in our training and test set 

Returns:
The predictions on the test data made by the classifier model based on the training data
'''
import re
from sklearn import metrics
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer

def nb_classifier(test_data,train_data,model):

  y_train = train_data["y"]                                         # Output label columns of training data
  y_test = test_data["y"]                                           # Output label columns of test data
  X_train = train_data["Review"]                                    # Output "review" (X) columns of training data
  X_test = test_data["Review"]                                      # Output "review" (X) columns of test data
  
  if model == "countvectorizer":
    method = CountVectorizer()
  elif model == "tfidfvectorizer":
    method = TfidfVectorizer(stop_words = "english", max_df=0.2)    # specifying the vectorizer to ignore stop words and maximum document freqency of value = 0.2
  
  method_train = method.fit_transform(X_train.values)               # Transform the training data using only the 'review' column values of training data: method_train 
  method_test = method.transform(X_test.values)                     # Transform the test data using only the 'review' column values of test data: count_test 

  nb_classifier = MultinomialNB()                                   # Instantiate a Multinomial Naive Bayes classifier: nb_classifier

  nb_classifier.fit(method_train, y_train)                          # Fit the classifier to the training data

  pred = nb_classifier.predict(method_test)                         # Create the predicted values: pred

  score = metrics.accuracy_score(y_test, pred)                      # Calculate the accuracy score: score
  return pred

# Predicting the labels of the validation dataset and finding the accuracy of prediction using Counte Vectorizer and Tfidf Vectorizer model

# Predicting labels of validation tablelled data using the Count Vectorizer nb_classifier 
pred_count_vecto_valid = nb_classifier(df_review_valid,df_review_train,"countvectorizer") 

# Calculating the accuracy of Count Vectorizer model
print("The accuracy using Count Vectorizer model is {0}".format(accuracy_val(y_valid,pred_count_vecto_valid))) 

# Predicting labels of validation tablelled data using the Tfidf Vectorizer nb_classifier 
pred_tfidf_vecto_valid = nb_classifier(df_review_valid,df_review_train,"tfidfvectorizer") 

# Calculating the accuracy of Tdidf Vectorizer model
print("The accuracy using Tfidf Vectorizer model is {0}".format(accuracy_val(y_valid,pred_tfidf_vecto_valid)))

"""We apply the NB classifier based on Count Vectorizer to our test data. """

pred = nb_classifier(df_test_review,df_review_train,"countvectorizer")
Predicted_2 = pd.DataFrame(pred, columns= ['Prediction'])
Predicted['Id'] = range(0,160)
Predicted_2 = Predicted[['Id', 'Prediction']]
Predicted_2

Predicted_2.to_csv("Predicted.csv")

!cp Predicted.csv "drive/My Drive/"

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !apt-get install texlive texlive-xetex texlive-latex-extra pandoc
# !pip install pypandoc

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # the red text is a placeholder! Change it to your directory structure!
# !cp 'drive/My Drive/Colab Notebooks/4740_FA21_p1_netid1_netid2.ipynb' ./

# the red text is a placeholder! Change it to the name of this notebook!
!jupyter nbconvert --to PDF "4740_FA21_p1_netid1_netid2.ipynb"
